# MCP Model Context Protocol 模型上下文协议

## 一、MCP基础概念

MCP（Model Context Protocol，模型上下文协议）是AI领域的一项重要开放标准，旨在简化大语言模型与外部数据和工具的连接过程。下面这个表格能帮你快速把握其核心要点。

| 方面         | MCP的核心要点                                                |
| ------------ | ------------------------------------------------------------ |
| **定位**     | AI领域的“万能插嘴”或标准化“交通规则”，用于大模型与外部系统通信。 |
| **核心架构** | 采用**主机(Host)-客户端(Client)-服务器(Server)** 三层架构。  |
| **关键特点** | 1. **标准化集成**：将集成复杂度从MxN降至M+N。  2. **即插即用**：工具可像USB设备一样即插即用。  3. **内置安全**：提供权限管控、敏感信息隔离等安全机制。 |
| **提供功能** | MCP服务器主要提供三类功能：**资源(Resources)**、**工具(Tools)** 和**提示(Prompts)**。 |
| **协议对比** | 区别于OpenAI等厂商各自的**Function Calling**实现，MCP是一个**与模型无关的开放标准**。 |

### 💻 详解MCP架构

MCP的架构是其实现“即插即用”能力的核心，主要包括三个角色：

- **MCP服务器（Server）**：这是能力的提供方。每个服务器都像一个专用的“适配器”，将某个特定的数据源或工具（如数据库、天气API、文件系统）的功能，按照MCP标准封装成统一的接口。
- **MCP客户端（Client）**：这是连接的桥梁。它内置于主机应用程序中，负责与一个或多个MCP服务器建立连接，并管理它们之间的通信。
- **MCP主机（Host）**：这是最终的用户界面。它是直接与用户交互的应用程序，例如Claude桌面端、Cursor编辑器等。主机通过集成的客户端来调用各个服务器提供的能力。

### ✨ MCP的独特优势

- **大幅降低开发复杂度**：在MCP出现之前，如果想让M个AI应用连接N个外部工具，需要开发M×N个连接器，工作量大且难以维护。MCP通过标准化协议，将问题简化为仅为M个应用和N个工具各开发一次适配器（M+N），之后所有兼容的应用和工具即可互通。
- **强大的安全控制**：MCP在设计上非常重视安全。它允许对每个服务器的访问权限进行精细控制（例如，只允许读取特定文件夹），并且敏感信息（如API密钥、数据库密码）可以保留在服务器端，无需传递给大模型厂商，有效降低了数据泄露的风险。
- **动态发现与灵活性**：MCP支持动态发现可用的工具和资源。这意味着当一个新的MCP服务器被添加到系统中时，客户端能够自动发现其提供的功能，无需修改主机应用的代码，实现了真正的“即插即用”。

### 🔌 MCP服务器提供的功能

MCP服务器主要提供三种类型的功能，极大扩展了大模型的能力边界：

1. **资源**：指类似文件的数据，如数据库中的记录、API的响应结果或本地文档。MCP允许大模型安全地读取这些资源以获取上下文信息。
2. **工具**：这是最核心的功能，指可以由大模型调用的函数。例如，创建一个日历事件、发送一封邮件、查询一次航班。工具的执行通常需要用户的明确批准。
3. **提示模板**：预定义的对话模板，可以帮助用户更高效地完成特定任务，例如生成周报或进行代码审查。

### ↔ 横向对比：MCP与其他协议

为了让你更清晰地理解MCP的定位，下面将其与相关概念进行对比：

| 特性         | **MCP (Model Context Protocol)**              | **传统API集成**            | **厂商特定的Function Calling**              |
| ------------ | --------------------------------------------- | -------------------------- | ------------------------------------------- |
| **协议性质** | **开放的、与模型无关的标准**                  | 每个API有自己的标准        | 厂商特定的私有实现（如OpenAI的`tools`参数） |
| **集成方式** | **一次性标准化集成**，所有兼容MCP的工具可复用 | 为每个API单独开发适配器    | 依赖特定模型的实现，切换模型可能需要重写    |
| **生态效应** | 构建开放、共享的工具生态                      | 形成数据孤岛，集成工作重复 | 被绑定在特定厂商的生态内                    |
| **核心优势** | 降低复杂度、促进互操作性、避免供应商锁定      | 灵活、直接                 | 与特定模型深度优化，可能性能更好            |

简单来说，Function Calling是一种**机制**，让大模型知道“何时”以及“如何”调用一个函数；而MCP则是一套**标准协议**，定义了这些函数“在哪里”以及“以何种形式”被提供，从而实现了跨模型、跨应用的函数共享和调用。

### 💎 总结与展望

总而言之，MCP通过引入标准化的“接口”，解决了AI应用与外部工具连接时的混乱和低效问题。它通过主机-客户端-服务器的解耦架构，显著降低了开发成本，并内置了安全特性。随着苹果、谷歌、OpenAI以及国内的百度、阿里、腾讯等巨头的纷纷支持，MCP正迅速成为AI智能体时代的基础设施标准，有望加速真正有用的AI应用大规模涌现。

## 二、使用Python实现的一个MCP 服务端

示例项目仓库地址：

https://github.com/zhuanzhu-li/ai-mcp.git

使用cursor生成，实现了简单的 PostgreSQL 数据库的连接以及数据查询。可以接入大模型使用自然语言进行数据的获取。
